{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old Documentation:\n",
    "\n",
    "- [`import`](https://docs.python.org/3/reference/simple_stmts.html#the-import-statement)\n",
    "- [`len`](https://docs.python.org/3/library/functions.html#len)\n",
    "- [`numpy`](https://numpy.org/doc/1.19/user/whatisnumpy.html)\n",
    "- [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html)\n",
    "- [numpy indexing](https://numpy.org/doc/stable/reference/arrays.indexing.html)\n",
    "- [`torch`](https://pytorch.org/docs/stable/index.html)\n",
    "- [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)\n",
    "- [`torch.utils.data`](https://pytorch.org/docs/stable/data.html#torch.utils.data)\n",
    "- [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the numpy and pytorch (torch) modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the sample dataset to be used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([ np.array([[ 2,  3,  4],\n",
    "                         [ 4,  6,  8],\n",
    "                         [ 6,  9, 12],\n",
    "                         [ 8, 12, 16]]),\n",
    "               np.array([[10, 15, 20],\n",
    "                         [12, 18, 24]]) ], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Code to be executed once at the beginning for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_(X):\n",
    "    \n",
    "    # Create a global variable of X to be accessed in other functions.\n",
    "    global global_X\n",
    "    global_X = X\n",
    "    \n",
    "    # Create a global variable to store the list of all (sample, row) index pairs.\n",
    "    global global_index_map\n",
    "    global_index_map = []\n",
    "    \n",
    "    # Use two for loops to create a list of all (sample, row) index pairs.\n",
    "    for i, x in enumerate(X):\n",
    "        for j, _ in enumerate(x):\n",
    "            index_pair = (i, j)\n",
    "            global_index_map.append(index_pair)\n",
    "    \n",
    "    # Create a global variable of the length of the list of pairs to be accessed in other functions\n",
    "    global global_length\n",
    "    global_length = len(global_index_map)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Code to return the number of items as length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_():\n",
    "\n",
    "    # Return the global variable of the length of the list of (sample, row) pairs\n",
    "    return global_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Code to return the x item at sample i, row j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem_(index):\n",
    "    \n",
    "    # Get the sample index i and row index j that corresponds to the pair index\n",
    "    i, j = global_index_map[index]\n",
    "    \n",
    "    # Index the global variable X using the sample index i and row index j\n",
    "    x_item = global_X[i][j, :]\n",
    "    \n",
    "    return x_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Code to return the collated list of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_(batch):\n",
    "    \n",
    "    # Index the global variable X at input index i    \n",
    "    batch = torch.as_tensor(batch)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to use init, len, getitem, and collate as functions. Here, we create a batch of size 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8, 12, 16],\n",
      "        [10, 15, 20],\n",
      "        [12, 18, 24],\n",
      "        [ 6,  9, 12]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dataset X\n",
    "init_(X)\n",
    "\n",
    "# Get the size of the dataset X\n",
    "dataset_size = len_()\n",
    "\n",
    "# Create a random sample of 4 indecies from the dataset X\n",
    "sample_size = 4\n",
    "sample_indices = np.random.choice(dataset_size, sample_size, replace=False)\n",
    "\n",
    "# Create an empty list to store batch items from X\n",
    "batch = []\n",
    "\n",
    "# Use a for loop to get all batch items\n",
    "for i in sample_indices:\n",
    "    batch.append(getitem_(i))\n",
    "    \n",
    "# Collate the list of batch items into a usable form\n",
    "batch = collate_fn_(batch)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to create a Dataset class using init, len, getitem and collate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, X):\n",
    "        \n",
    "        ### Code to be executed once at the beginning for initialization\n",
    "        self.X = X\n",
    "        \n",
    "        self.index_map = []\n",
    "        for i, x in enumerate(X):\n",
    "            for j, _ in enumerate(x):\n",
    "                index_pair = (i, j)\n",
    "                self.index_map.append(index_pair)\n",
    "        \n",
    "        self.length = len(self.index_map)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        ### Return the number of items as length\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        ### Return one item at recording i, timestep j\n",
    "        i, j = global_index_map[index]\n",
    "        x_item = global_X[i][j, :]\n",
    "\n",
    "        return x_item\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        \n",
    "        ### Specify how to collate list of items and what to return\n",
    "        batch = torch.as_tensor(batch)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to use the dataset class and create a batch of size 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8, 12, 16],\n",
      "        [ 2,  3,  4],\n",
      "        [ 6,  9, 12],\n",
      "        [ 4,  6,  8]])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the dataset class object\n",
    "dataset = ExampleDataset(X)\n",
    "\n",
    "# Create a random sample of 4 indecies from the dataset\n",
    "sample_size = 4\n",
    "sample_indices = np.random.choice(len(dataset), sample_size, replace=False)\n",
    "\n",
    "# Create an empty list to store batch items from the dataset\n",
    "batch = []\n",
    "\n",
    "# Use a for loop to get all batch items\n",
    "for i in sample_indices:\n",
    "    batch.append(dataset[i])\n",
    "    \n",
    "# Collate the list of batch items into a usable form\n",
    "batch = ExampleDataset.collate_fn(batch)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The example provided does not take advantage of \"multithreading\". When a dataset class is combined with a data loader class, you are able to use multithreading and dramatically increase your data loading performance. The data loader class is covered in a future tutorial of this series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 3.6",
   "language": "python",
   "name": "pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
